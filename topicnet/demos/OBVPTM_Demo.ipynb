{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from topicnet.cooking_machine.dataset import dataset2counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mytopicnet/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "from topicnet.embeddings.keyed_vectors import (\n",
    "    get_doc_vec_phi, get_doc_vec_keyedvectors, topic_model_to_keyed_vectors, calc_dataset_statistics\n",
    ")\n",
    "from topicnet.cooking_machine.models import TopicModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the \"ARTM_150_Base\" model...\n",
      "100%|██████████| 42.0M/42.0M [00:00<00:00, 96.9MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from topicnet.embeddings.api import load_model\n",
    "\n",
    "any_model = load_model(\"ARTM_150_Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторные представления слов позволяют выразить семантическую похожесть/связь слов через пространственные отношения между векторами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyed_vectors = topic_model_to_keyed_vectors(any_model, \"@lemmatized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример векторного представления слова \"библия\" (то есть эмбеддинг слова \"библия\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9459379e-05, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 5.7174258e-15, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.6374557e-08, 4.9805258e-05, 9.1217656e-16, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0916889e-06,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2708416e-04,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.5917989e-05,\n",
       "       1.3626588e-11, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.1377406e-05, 0.0000000e+00, 1.7141596e-04, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       2.3118336e-14, 4.4071062e-09, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 2.8508982e-15, 0.0000000e+00,\n",
       "       0.0000000e+00, 3.0577880e-07, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.2948043e-10,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 9.6275850e-05, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.2794759e-06,\n",
       "       0.0000000e+00, 2.1302892e-04, 0.0000000e+00, 2.5128415e-05,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0191138e-13, 0.0000000e+00, 0.0000000e+00, 3.3280095e-13,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 3.4125114e-09, 0.0000000e+00, 0.0000000e+00,\n",
       "       4.3746686e-06, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 3.4365508e-05, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.3071157e-07,\n",
       "       0.0000000e+00, 0.0000000e+00, 2.5979005e-13, 0.0000000e+00,\n",
       "       7.4987466e-13, 2.1827628e-15, 2.9727781e-08, 0.0000000e+00,\n",
       "       4.8763433e-09, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 3.3879654e-14, 7.2309948e-16,\n",
       "       1.6950627e-05, 0.0000000e+00, 1.6383878e-10, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 4.3974364e-16, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 6.3592081e-05, 1.5472342e-05,\n",
       "       0.0000000e+00, 2.6993534e-05, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 7.1599825e-06], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.get_vector(\"библия\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В контексте тематических эмбеддингов, построенных на основе статей Википедии, два слова будут близки в случае, если они часто встречаются в похожих статьях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33605382"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оба этих слова связаны со статьями Википедии про различные персоналии\n",
    "\n",
    "keyed_vectors.similarity(\"родиться\", \"фильмография\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026072497"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.similarity(\"космос\", \"галактика\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005496593"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.similarity(\"валюта\", \"биржа\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7197375e-05"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.similarity(\"сцена\", \"польша\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример задачи, решаемой эмбеддингами слов: определение лишнего слова в наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'интерференция'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.doesnt_match([\"жена\", \"год\", \"встреча\", \"орден\", \"интерференция\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'церковь'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.doesnt_match([\"паук\", \"муха\", \"млекопитающее\", \"церковь\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'млекопитающее'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.doesnt_match([\"паук\", \"муха\", \"млекопитающее\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'микроскоп'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyed_vectors.doesnt_match([\"сингл\", \"концерт\", \"чарт\", \"микроскоп\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## document embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document embedding via averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторные представления документов также полезны для прикладных задач. Рассмотрим задачу обнаружения парафраз (http://paraphraser.ru): по двум новостным заголовкам требуется определить, говорят ли они об одном и том же событии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_paraphraser = Dataset(\"/home/bulatov/nelder_mead/paraphraser_dataset.csv\",  internals_folder_path=\"/home/bulatov/nelder_mead/paraphraser_dataset\")\n",
    "paraphraser_counter = dataset2counter(dataset_paraphraser)\n",
    "dict_parap = calc_dataset_statistics(dataset_paraphraser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    (\n",
    "        Counter({'задержать': 1, 'в': 1, 'москва': 1, 'американский': 1, 'шпион': 1, 'скрываться': 1, 'изменять': 1, 'внешность': 1}), \n",
    "        Counter({'опубликовать': 1, 'видео': 1, 'задержание': 1, 'американский': 1, 'шпион': 1, 'в': 1, 'москва': 1}),\n",
    "        0\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        Counter({'синоптик': 1, 'зафиксировать': 1, 'в': 1, 'москва': 1, 'рекордный': 1, 'сугроб': 1}),\n",
    "        Counter({'на': 1, 'москва': 1, 'выпасть': 1, '0,1': 1, 'зима': 1}),\n",
    "        -1\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        Counter({'законопроект': 1, 'о': 1, 'национализация': 1, 'имущество': 1, 'рф': 1, 'на': 1, 'украина': 1, 'внести': 1, 'в': 1, 'раду': 1}),\n",
    "        Counter({'в': 1, 'раду': 1, 'внести': 1, 'законопроект': 1, 'о': 1, 'национализация': 1, 'имущество': 1, 'россия': 1}),\n",
    "        1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторные представления документов можно получить усреднением эмбеддингов всех слов, содержающихся в нём. Рассмотрим две схемы усреднения: с одинаковыми весами или усреднение на основе статистики вхождения слова в разные документы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "true_label =  0\n",
      "Counter({'задержать': 1, 'в': 1, 'москва': 1, 'американский': 1, 'шпион': 1, 'скрываться': 1, 'изменять': 1, 'внешность': 1})\n",
      "Counter({'опубликовать': 1, 'видео': 1, 'задержание': 1, 'американский': 1, 'шпион': 1, 'в': 1, 'москва': 1})\n",
      "{'unit': 0.31887765811145047, 'tf-idf': 0.23546726628676873}\n",
      "\n",
      "true_label =  -1\n",
      "Counter({'синоптик': 1, 'зафиксировать': 1, 'в': 1, 'москва': 1, 'рекордный': 1, 'сугроб': 1})\n",
      "Counter({'на': 1, 'москва': 1, 'выпасть': 1, '0,1': 1, 'зима': 1})\n",
      "{'unit': 0.3715961955866923, 'tf-idf': 0.17331172489455154}\n",
      "\n",
      "true_label =  1\n",
      "Counter({'законопроект': 1, 'о': 1, 'национализация': 1, 'имущество': 1, 'рф': 1, 'на': 1, 'украина': 1, 'внести': 1, 'в': 1, 'раду': 1})\n",
      "Counter({'в': 1, 'раду': 1, 'внести': 1, 'законопроект': 1, 'о': 1, 'национализация': 1, 'имущество': 1, 'россия': 1})\n",
      "{'unit': 0.37454990501442825, 'tf-idf': 0.6490250998283357}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dict_df = dict_parap\n",
    "vec = keyed_vectors\n",
    "\n",
    "for pair in docs:\n",
    "    res = {}\n",
    "    for avg_scheme in ['unit', \"tf-idf\"]:\n",
    "        v1 = get_doc_vec_keyedvectors(vec, pair[0], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        v2 = get_doc_vec_keyedvectors(vec, pair[1], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        predicted_val = cosine_similarity(v1, v2)[0][0]\n",
    "        res[avg_scheme] = predicted_val\n",
    "    print()\n",
    "    print(\"true_label = \", pair[2])\n",
    "    print(pair[0])\n",
    "    print(pair[1])\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднение с весами tf-idf делает эмбеддинг документа более устойчивым к частым, но неинформативным словам и помогает подстроить эмбеддинги документов под коллекцию с нетипичной лекской. \n",
    "\n",
    "Сходство первой и второй документовой пары уменьшилось, что соответствует меткам \"0\" и \"-1\". Третья пара документов, напротив, увеличила своё сходство (что соответствует метке \"+1\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что разные стратегии усреднения действительно влияют на полученные документные эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit 0.37454990501442825\n",
      "0.013826804489552768 0.007170047072100804\n",
      "0.005285812316287775 0.0017499953202786856\n",
      "tf-idf 0.6490250998283357\n",
      "0.08219843898783698 0.06043779218852825\n",
      "0.021489167828500893 0.015217080430011265\n"
     ]
    }
   ],
   "source": [
    "# different averaging has an influence on the vectors and their cosine distance\n",
    "\n",
    "\n",
    "for avg_scheme in ['unit', \"tf-idf\"]:\n",
    "    v1 = get_doc_vec_keyedvectors(vec, pair[0], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "    v2 = get_doc_vec_keyedvectors(vec, pair[1], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "    predicted_val = cosine_similarity(v1, v2)[0][0]\n",
    "    print(avg_scheme, predicted_val)\n",
    "    print(sum(v1[0]), sum(v2[0]))\n",
    "    print(max(v1[0]), max(v2[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mytopicnet)",
   "language": "python",
   "name": "conda_mytopicnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
