{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка качества тематических эмбеддингов, основанная на задаче определения перефразирования. Будет использован общедоступный корпус парафраз (проект http://paraphraser.ru/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download the Paraphraser dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала нужно скачать и предобработать этот корпус. \n",
    "\n",
    "Предобработка: парсинг XML, токенизация, лемматизация, подсчёт частот слов внутри одного документа, создание `TopicNet.Dataset` (который будет хранить информацию о частотах слов внутри всего корпуса).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://paraphraser.ru/download/get?file_id=1\n",
    "! unzip get?file_id=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "with open(\"paraphrases.xml\", \"rb\") as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "PT = etree.fromstring(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "texts = {}\n",
    "\n",
    "for i, paraphrase in enumerate(PT.getchildren()[1].getchildren()):\n",
    "    data = {\n",
    "        child.get('name'): child.text \n",
    "        for child in \n",
    "        paraphrase.getchildren()\n",
    "    }\n",
    "    key = data['id_1'], data['id_2']\n",
    "    classes[key] = data['class']\n",
    "    texts[key[0]] = data['text_1']\n",
    "    texts[key[1]] = data['text_2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def vowpalize_sequence(sequence):\n",
    "    word_2_frequency = Counter(sequence)\n",
    "    del word_2_frequency['']\n",
    "    vw_string = ''\n",
    "\n",
    "    for word in word_2_frequency:\n",
    "        vw_string += word + \":\" + str(word_2_frequency[word]) + ' '\n",
    "    return vw_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _find_next_token_func(line, start_ind, regexp):\n",
    "    m = regexp.search(line, start_ind)\n",
    "    if m:\n",
    "        start_ind, length = m.start(), len(m.group())\n",
    "    else:\n",
    "        start_ind, length = start_ind, 0\n",
    "    return start_ind, length\n",
    "\n",
    "def find_indexes(string, regexp):\n",
    "    \"\"\"\n",
    "    Find indexes of all tokens in string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "        String, supposed to be a sentence or something analogous\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index_list : list of int\n",
    "        List of indexes. Even indexes are word start positions, uneven indexes are word lengths.\n",
    "    \"\"\"\n",
    "    index_list = []\n",
    "    start_ind, length = 0, 0\n",
    "    while True:\n",
    "        start_ind, length = _find_next_token_func(string, start_ind + length, regexp)\n",
    "        if length == 0:\n",
    "            break\n",
    "        index_list.append((start_ind, length))\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_RU_TOKEN_REGEX = re.compile(\n",
    "    '''(?:-|[^a-zа-яё\\s\"'\"\"«»„“-]+|[0-9a-zа-яё_]+(-?[0-9a-zа-яё_]+)*)''',\n",
    "    re.IGNORECASE | re.UNICODE)\n",
    "import string\n",
    "\n",
    "\n",
    "def tokenize(the_string, regexp=BASE_RU_TOKEN_REGEX):\n",
    "    index_list = find_indexes(the_string, regexp)\n",
    "\n",
    "    tokenized_string = [\n",
    "        the_string[ind_start:ind_start + length]\n",
    "        for ind_start, length in index_list\n",
    "    ]\n",
    "    return [part.replace(\":\", \"%3A\") for part in tokenized_string if part not in string.punctuation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_paraphraser_dataset = pd.DataFrame(index=texts.keys(), columns=['raw_text', 'vw_text'])\n",
    "\n",
    "\n",
    "\n",
    "for idx, text in texts.items():\n",
    "    sequence = [morph.parse(w)[0][2] for w in tokenize(text)]\n",
    "    lemmatized = '@lemmatized ' + vowpalize_sequence(sequence)\n",
    "    vw_string = ' |'.join([idx, lemmatized])\n",
    "    \n",
    "    lemmatized_paraphraser_dataset.loc[idx, 'raw_text'] = text\n",
    "    lemmatized_paraphraser_dataset.loc[idx, 'vw_text'] = vw_string\n",
    "\n",
    "\n",
    "lemmatized_paraphraser_dataset.index.rename(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним результаты (датасет и метки классов).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "\n",
    "\n",
    "with open(\"classes_paraphraser.json\", \"w\") as f:\n",
    "    ujson.dump(classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine import Dataset\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dataframe(lemmatized_paraphraser_dataset, \"./paraphraser_dataset\")\n",
    "dataset._data.to_csv(\"paraphraser_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the Paraphraser dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и метки классов, вычислим некоторые статистики частот слов, скачаем модель из библиотеки ОБВПТМ и изучим её поведение на данной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "import ujson\n",
    "\n",
    "\n",
    "with open(\"classes_paraphraser.json\", \"r\") as f:\n",
    "    classes_raw = ujson.load(f)\n",
    "    \n",
    "classes = {\n",
    "    literal_eval(k): literal_eval(v)\n",
    "    for k, v in classes_raw.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from topicnet.cooking_machine.dataset import dataset2counter\n",
    "\n",
    "from topicnet.cooking_machine import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "dataset_paraphraser = Dataset(\"paraphraser_dataset.csv\",  internals_folder_path=\"./paraphraser_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphraser_counter = dataset2counter(dataset_paraphraser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mytopicnet/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "from topicnet.embeddings.keyed_vectors import (\n",
    "    get_doc_vec_phi, get_doc_vec_keyedvectors, topic_model_to_keyed_vectors, calc_dataset_statistics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_parap = calc_dataset_statistics(dataset_paraphraser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.models import TopicModel\n",
    "\n",
    "\n",
    "any_model = load_model(\"ARTM_150_Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов в корпусе принимают одно из трёх возможных значений: \n",
    "* -1: разные по смыслу новости  (\"80% жителей России поддерживают антитабачный закон\" и \"Госдума приняла антитабачный законопроект во втором чтении\")\n",
    "* 0: похожие по смыслу новости (\"ЦИК хочет отказаться от электронной системы подсчета голосов\" и \"ЦИК может отказаться от электронной системы подсчета голосов\")\n",
    "* 1: одинаковые по смыслу новости (\"СК выяснит, был ли подкуп свидетеля по делу Ю.Буданова\" и \"СК проверит информацию о подкупе свидетеля по делу об убийстве Буданова\")\n",
    "\n",
    "Для того, чтобы оценить качество эмбеддингов, будем измерять корреляцию Спирмана между эталонными метками и метками, предсказанными моделью (как косинусная близость между эмбеддингами заголовков).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_document_task_avg(model, phi, classes, dict_df, counter, avg_scheme=\"unit\"):\n",
    "    predicted = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pair, value in classes.items():\n",
    "        v1 = get_doc_vec_phi(phi, counter[pair[0]], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        v2 = get_doc_vec_phi(phi, counter[pair[1]], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        predicted_val = cosine_similarity(v1, v2)[0][0]\n",
    "        value = int(value)\n",
    "        true_labels.append(value)\n",
    "        # bins[value].append(predicted_val)\n",
    "        predicted.append(predicted_val)\n",
    "\n",
    "    return spearmanr(predicted, true_labels)[0]\n",
    "\n",
    "        \n",
    "def measure_document_task_theta(model, classes, dataset):\n",
    "    theta = model.get_theta(dataset=dataset)\n",
    "    predicted = []\n",
    "    true_labels = []\n",
    "\n",
    "    sp = model.specific_topics\n",
    "\n",
    "    for pair, value in classes.items():\n",
    "        v1 = (theta.loc[sp, pair[0]].values.reshape(1, -1))\n",
    "        v2 = (theta.loc[sp, pair[1]].values.reshape(1, -1))\n",
    "        predicted_val = cosine_similarity(v1, v2)[0][0]\n",
    "        value = int(value)\n",
    "        true_labels.append(value)\n",
    "        # bins[value].append(predicted_val)\n",
    "        predicted.append(predicted_val)\n",
    "\n",
    "    return spearmanr(predicted, true_labels)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3525540032601885"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_document_task_avg(any_model, any_model.get_phi(), classes, dict_parap, paraphraser_counter, \"unit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37121453978036173"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_document_task_avg(any_model, any_model.get_phi(), classes, dict_parap, paraphraser_counter, \"tf-idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3045784415119519"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_document_task_theta(any_model, classes, dataset_paraphraser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что документные эмбеддинги, полученные из столбцов матрицы Тета (то есть вычисленные при помощи ЕМ-алгоритма), уступают по качеству документным эмбеддингам, построенным при помощи усреднения векторов слов. Также отметим, что усреднение при помощи tf-idf весов увеличивает качество по сравнению с \"простым\" усреднением.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОБВПТМ может быть полезен и для работы с традиционными (не-тематическими) эмбеддингами, поскольку предоставляет возможность вычислять эмбеддинг документа различными способами (что не позволяет сделать GenSim).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import navec\n",
    "\n",
    "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "\n",
    "vec = navec.Navec.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def measure_document_task_kv(vec, classes, dict_df, counter, avg_scheme=\"unit\"):\n",
    "    predicted = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pair, value in classes.items():\n",
    "        v1 = get_doc_vec_keyedvectors(vec, counter[pair[0]], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        v2 = get_doc_vec_keyedvectors(vec, counter[pair[1]], dict_df, avg_scheme).values.reshape(1, -1)\n",
    "        predicted_val = cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "        value = int(value)\n",
    "        true_labels.append(value)\n",
    "        predicted.append(predicted_val)\n",
    "    return spearmanr(predicted, true_labels)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5617694371502122 0.5994033884599912\n"
     ]
    }
   ],
   "source": [
    "qual_tfidf = measure_document_task_kv(vec, classes, dict_parap, paraphraser_counter, \"tf-idf\")\n",
    "\n",
    "qual_base = measure_document_task_kv(vec, classes, dict_parap, paraphraser_counter, \"unit\")\n",
    "\n",
    "print(qual_base, qual_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остаётся справедливым наблюдение о том, что усреднение при помощи tf-idf весов увеличивает качество по сравнению с \"простым\" усреднением.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОБВПТМ позволяет преобразовать тематическую модель в объект `Gensim.KeyedVectors` и работать с этим объектом, как с традиционным эмбеддингом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = topic_model_to_keyed_vectors(any_model, \"@lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30905862857638616 0.3148957860011381\n"
     ]
    }
   ],
   "source": [
    "qual_tfidf = measure_document_task_kv(vec2, classes, dict_parap, paraphraser_counter, \"tf-idf\")\n",
    "\n",
    "qual_base = measure_document_task_kv(vec2, classes, dict_parap, paraphraser_counter, \"unit\")\n",
    "\n",
    "print(qual_base, qual_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(разница численных значений связана с неодинаковой обработкой фоновых тем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mytopicnet)",
   "language": "python",
   "name": "conda_mytopicnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
